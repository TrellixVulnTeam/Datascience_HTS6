{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Discrete Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(x, w, p=0, s=1):\n",
    "    w_rot = np.array(w[::-1])\n",
    "    x_padded = np.array(x)\n",
    "    if p > 0:\n",
    "        zero_pad = np.zeros(shape=p)\n",
    "        x_padded = np.concatenate([zero_pad, x_padded, zero_pad])\n",
    "    res = []\n",
    "    for i in range(0, int(len(x)/s), s):\n",
    "        res.append(np.sum(x_padded[i:i+w_rot.shape[0]] * w_rot))\n",
    "    return np.array(res)\n",
    "\n",
    "# Testing:\n",
    "x = [1, 3, 2, 4, 5, 6, 1, 3]\n",
    "w = [1, 0, 3, 1, 2]\n",
    "\n",
    "print('Conv1d Implementation:', conv1d(x, w, p=2, s=1))\n",
    "print('Numpy Results:', np.convolve(x, w, mode='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "def conv2d(X, W, p=(0, 0), s=(1, 1)):\n",
    "    W_rot = np.array(W)[::-1, ::-1]\n",
    "    X_orig = np.array(X)\n",
    "    n1 = X_orig.shape[0] + 2 * p[0]\n",
    "    n2 = X_orig.shape[1] + 2 * p[1]\n",
    "    X_padded = np.zeros(shape=(n1, n2))\n",
    "    X_padded[p[0]:p[0]+X_orig.shape[0], p[1]:p[1]+X_orig.shape[1]] = X_orig\n",
    "\n",
    "    res = []\n",
    "    for i in range(0, int((X_padded.shape[0] - W_rot.shape[0])/s[0])+1, s[0]):\n",
    "        res.append([])\n",
    "        for j in range(0, int((X_padded.shape[1]\\\n",
    "                               - W_rot.shape[1])/s[1]) + 1, s[1]):\n",
    "            X_sub = X_padded[i:i+W_rot.shape[0], j:j+W_rot.shape[1]]\n",
    "            res[-1].append(np.sum(X_sub * W_rot))\n",
    "    return(np.array(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1, 3, 2, 4], [5, 6, 1, 3], [1, 2, 0, 2], [3, 4, 3, 2]]\n",
    "W = [[1, 0, 3], [1, 2, 1], [0, 1, 1]]\n",
    "\n",
    "print('Conv2d Implementation:\\n', conv2d(X, W, p=(1, 1), s=(1, 1)))\n",
    "print('SciPy Results:\\n', scipy.signal.convolve2d(X, W, mode='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "img = imageio.imread('./example-image.png', pilmode='RGB')\n",
    "print('Image shape:', img.shape)\n",
    "print('Number of channels:', img.shape[2])\n",
    "print('Image data type:', img.dtype)\n",
    "print(img[100:102, 100:102, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a CNN with Low-Level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(\n",
    "        path, f'{kind}-labels-idx1-ubyte'\n",
    "    )\n",
    "    images_path = os.path.join(\n",
    "        path, f'{kind}-images-idx3-ubyte'\n",
    "    )\n",
    "    \n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    "        images = ((images / 255.) - .5) * 2\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "X_data, y_data = load_mnist('./mnist/', kind='train')\n",
    "print(f'Rows: {X_data.shape[0]},  Columns: {X_data.shape[1]}')\n",
    "X_test, y_test = load_mnist('./mnist/', kind='t10k')\n",
    "print(f'Rows: {X_test.shape[0]},  Columns: {X_test.shape[1]}')\n",
    "\n",
    "X_train, y_train = X_data[:1000, :], y_data[:1000]\n",
    "X_valid, y_valid = X_data[1000:1500, :], y_data[1000:1500]\n",
    "X_test, y_test = X_test[:500, :], y_test[:500]\n",
    "\n",
    "print('Training:   ', X_train.shape, y_train.shape)\n",
    "print('Validation: ', X_valid.shape, y_valid.shape)\n",
    "print('Test Set:   ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size=64, shuffle=False, random_seed=None):\n",
    "    \n",
    "    idx = np.arange(y.shape[0])\n",
    "    \n",
    "    if shuffle:\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "        rng.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "    \n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        yield (X[i:i + batch_size, :], y[i:i + batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals)/std_val\n",
    "X_valid_centered = (X_valid - mean_vals)/std_val\n",
    "X_test_centered = (X_test - mean_vals)/std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnlowlevel import conv_layer\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "    conv_layer(x, name='convtest', kernel_size=(3, 3), n_output_channels=32)\n",
    "    \n",
    "del g, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnlowlevel import fc_layer\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "    fc_layer(x, name='fctest', n_output_units=32, activation_fn=tf.nn.relu)\n",
    "\n",
    "del g, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnlowlevel import build_cnn\n",
    "\n",
    "# Define random seed\n",
    "random_seed = 123\n",
    "\n",
    "# create a graph\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf.set_random_seed(random_seed)\n",
    "    # build the graph\n",
    "    build_cnn()\n",
    "\n",
    "    # saver:\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnlowlevel import train, save\n",
    "\n",
    "# create a TF session and train the CNN model\n",
    "with tf.Session(graph=g) as sess:\n",
    "    train(\n",
    "        sess,\n",
    "        training_set=(X_train_centered, y_train), \n",
    "        validation_set=(X_valid_centered, y_valid), \n",
    "        initialize=True, random_seed=123\n",
    "    )\n",
    "    save(saver, sess, epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnlowlevel import load, predict\n",
    "\n",
    "del g\n",
    "\n",
    "# Calculate prediction accuracy on test set restoring the saved model\n",
    "# create a new graph and build the model\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    tf.set_random_seed(random_seed)\n",
    "    # build the graph\n",
    "    build_cnn()\n",
    "\n",
    "    # saver:\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "# create a new session and restore the model\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    load(saver, sess, epoch=20, path='./model/')\n",
    "    \n",
    "    preds = predict(sess, X_test_centered, return_proba=False)\n",
    "    print(f'Test Accuracy: {(100 * np.sum(preds == y_test)/len(y_test)):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the prediction on some test samples\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    load(saver, sess, epoch=20, path='./model/')\n",
    "        \n",
    "    print(predict(sess, X_test_centered[:10], return_proba=False))\n",
    "    print(predict(sess, X_test_centered[:10], return_proba=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue training for 20 more epochs without re-initializing\n",
    "# i.e. initialize=False\n",
    "\n",
    "# create a new session and restore the model\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    load(saver, sess, epoch=20, path='./model/')\n",
    "\n",
    "    train(\n",
    "        sess,\n",
    "        training_set=(X_train_centered, y_train), \n",
    "        validation_set=(X_valid_centered, y_valid),\n",
    "        initialize=False,\n",
    "        epochs=20, random_seed=123\n",
    "    )\n",
    "\n",
    "    save(saver, sess, epoch=40, path='./model/')\n",
    "\n",
    "    preds = predict(sess, X_test_centered, return_proba=False)\n",
    "\n",
    "    print(f'Test Accuracy: {(100 * np.sum(preds == y_test) / len(y_test)):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a CNN with `Layers` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnlayers import ConvNN\n",
    "\n",
    "cnn = ConvNN(random_seed=123)\n",
    "\n",
    "# train the model\n",
    "cnn.train(\n",
    "    training_set=(X_train_centered, y_train), \n",
    "    validation_set=(X_valid_centered, y_valid),\n",
    "    initialize=True\n",
    ")\n",
    "cnn.save(epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cnn\n",
    "\n",
    "cnn2 = ConvNN(random_seed=123)\n",
    "cnn2.load(epoch=20, path='./tflayers-model/')\n",
    "\n",
    "print(cnn2.predict(X_test_centered[:10, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cnn2.predict(X_test_centered)\n",
    "\n",
    "print(f'Test Accuracy: {(100 * np.sum(y_test == preds) / len(y_test)):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
