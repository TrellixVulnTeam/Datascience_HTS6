{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlining Workflows with Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "                 'machine-learning-databases'\n",
    "                 '/breast-cancer-wisconsin/wdbc.data',\n",
    "                 header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels\n",
    "X = df.loc[:, 2:].values\n",
    "y = df.loc[:, 1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check encodings:\n",
    "le.transform(['M', 'B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training and test setss\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# scale data, compress data, and initialize logreg model in a pipeline\n",
    "pipe_lr = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=2),\n",
    "    LogisticRegression(random_state=1, solver='liblinear')\n",
    ")\n",
    "\n",
    "# fit logreg model\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "\n",
    "# calculate accuracy\n",
    "print(f'Test Accuracy: {pipe_lr.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross-Validation to Assess Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# initialize stratified k-fold iterator\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=1).split(X_train, y_train)\n",
    "scores = []\n",
    "\n",
    "# iterate through the k folds to fit logreg model\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    # calculate accuracy\n",
    "    score = pipe_lr.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print(f'Fold: {k+1}, Class dist.: {np.bincount(y_train[train])}, Acc: {score:.3f}')\n",
    "\n",
    "# calculate average accuracy and std dev\n",
    "print(f'\\nCV accuracy: {np.mean(scores):.3f} +/- {np.std(scores):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# score k-fold cross-validator using scikit-learn\n",
    "scores = cross_val_score(estimator=pipe_lr,\n",
    "                         X=X_train, y=y_train,\n",
    "                         cv=10, n_jobs=1)\n",
    "\n",
    "print(f'CV accuracy scores: {scores}')\n",
    "print(f'\\nCV accuracy: {np.mean(scores):.3f} +/- {np.std(scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Algorithms with Learning and Validation Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosing Bias and Variance Problems with Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# scale data and initialize logreg model\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        LogisticRegression(penalty='l2', random_state=1, solver='liblinear'))\n",
    "\n",
    "# generate learning curves using 10 even training set intervals\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator=pipe_lr, X=X_train, y=y_train,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=10, n_jobs=1)\n",
    "\n",
    "# calculate average accuracies and std deviations\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(train_sizes, train_mean, color='blue',\n",
    "         marker='o', markersize=5, label='training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--',\n",
    "         marker='s', markersize=5, label='validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Over- and Underfitting with Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# set value range for C\n",
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "# generate validation curve plots for all C\n",
    "train_scores, test_scores = validation_curve(\n",
    "    estimator=pipe_lr, X=X_train, y=y_train,\n",
    "    param_name='logisticregression__C',\n",
    "    param_range=param_range, cv=10)\n",
    "\n",
    "# calculate average accuracies and std deviationss\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(param_range, train_mean, color='blue',\n",
    "         marker='o', markersize=5, label='training accuracy')\n",
    "plt.fill_between(param_range, train_mean + train_std, train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "plt.plot(param_range, test_mean, color='green', linestyle='--',\n",
    "         marker='s', markersize=5, label='validation accuracy')\n",
    "plt.fill_between(param_range, test_mean + test_std, test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.8, 1.03])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Machine Learning Models via Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters via grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# scale data and initialize support vector machine\n",
    "pipe_svc = make_pipeline(StandardScaler(), SVC(random_state=1))\n",
    "\n",
    "# set value ranges for parameters\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "# create dictionary: C for linear SVM, C and gamma for RBF kernel SVM\n",
    "param_grid = [{'svc__C': param_range, 'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, 'svc__gamma': param_range, 'svc__kernel': ['rbf']}]\n",
    "\n",
    "# initialize and fit grid search\n",
    "gs = GridSearchCV(estimator=pipe_svc,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "# find best performing model's accuracy and parameters\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate performance of best performing model\n",
    "clf = gs.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "print(f'Test accuracy: {clf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Selection with Nested Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize grid search\n",
    "gs = GridSearchCV(estimator=pipe_svc,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=2)\n",
    "\n",
    "# fit grid search using nested cross validation\n",
    "scores = cross_val_score(gs, X_train, y_train, scoring='accuracy', cv=5)\n",
    "\n",
    "# calculate average accuracy and std deviation\n",
    "print(f'CV accuracy: {np.mean(scores):.3f} +/- {np.std(scores):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# initialize grid search\n",
    "gs = GridSearchCV(estimator=DecisionTreeClassifier(random_state=0),\n",
    "                  param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6, 7, None]}],\n",
    "                  scoring='accuracy',\n",
    "                  cv=2)\n",
    "\n",
    "# fit grid search using nested cross validation\n",
    "scores = cross_val_score(gs, X_train, y_train, scoring='accuracy', cv=5)\n",
    "print(f'CV accuracy: {np.mean(scores):.3f} +/- {np.std(scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pipe_svc.fit(X_train, y_train)\n",
    "y_pred = pipe_svc.predict(X_test)\n",
    "\n",
    "# create confusion matrix\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i,\n",
    "                s=confmat[i, j],\n",
    "                va='center', ha='center')\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Prevision and Recall of Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "print(f'Precision: {precision_score(y_true=y_test, y_pred=y_pred):.3f}')\n",
    "print(f'Recall: {recall_score(y_true=y_test, y_pred=y_pred):.3f}')\n",
    "print(f'F1: {f1_score(y_true=y_test, y_pred=y_pred):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# construct own scorer using f1 score\n",
    "scorer = make_scorer(f1_score, pos_label=0)\n",
    "\n",
    "# initialize and fit grid search\n",
    "gs = GridSearchCV(estimator=pipe_svc,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring=scorer,\n",
    "                  cv=10)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a Receiver Operating Characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "# scale data, compress data, and initialize logreg model\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=2),\n",
    "                        LogisticRegression(penalty='l2', solver='liblinear', random_state=1, C=100.0))\n",
    "\n",
    "X_train2 = X_train[:, [4, 14]]\n",
    "\n",
    "# initialize stratified k-fold iterator\n",
    "cv = list(StratifiedKFold(n_splits=3, random_state=1).split(X_train, y_train))\n",
    "\n",
    "# initialize mean true positive rate and false positive rate\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "# for each fold ...\n",
    "for i, (train, test) in enumerate(cv):\n",
    "    # ... fit logreg model, \n",
    "    probas = pipe_lr.fit(X_train2[train], y_train[train]).predict_proba(X_train2[test])\n",
    "    # ... calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_train[test], probas[:, 1], pos_label=1)\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    # ... calculate area under curve\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # ... plot curve\n",
    "    plt.plot(fpr, tpr, label=f'ROC fold {i+1} (area = {roc_auc:.2f})')\n",
    "\n",
    "# calculate mean ROC\n",
    "mean_tpr /= len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "# plot random guessing, mean ROC, and perfect performance\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color=(0.6, 0.6, 0.6), label='random guessing')\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--', label=f'mean ROC (area = {roc_auc:.2f})', lw=2)\n",
    "plt.plot([0, 0, 1], [0, 1, 1], linestyle=':', color='black', label='perfect performance')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Metrics for Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct own scorer precision score\n",
    "pre_scorer = make_scorer(score_func=precision_score, pos_label=1, greater_is_better=True, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and fit grid search\n",
    "gs = GridSearchCV(estimator=pipe_svc,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring=pre_scorer,\n",
    "                  cv=10)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create imbalanced data\n",
    "X_imb = np.vstack((X[y == 0], X[y == 1][:40]))\n",
    "y_imb = np.hstack((y[y == 0], y[y == 1][:40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of always predicting `0` (benign)\n",
    "y_pred = np.zeros(y_imb.shape[0])\n",
    "np.mean(y_pred == y_imb) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "print('Number of class 1 samples before:', X_imb[y_imb == 1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample `1` (malignant)\n",
    "X_upsampled, y_upsampled = resample(X_imb[y_imb == 1], y_imb[y_imb == 1], replace=True,\n",
    "                                    n_samples=X_imb[y_imb == 0].shape[0], random_state=123)\n",
    "print('Number of class 1 samples after:', X_upsampled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack original samples of `0` with upsampled subset of `1`\n",
    "X_bal = np.vstack((X[y == 0], X_upsampled))\n",
    "y_bal = np.hstack((y[y == 0], y_upsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of always predicting `0` (benign)\n",
    "y_pred = np.zeros(y_bal.shape[0])\n",
    "np.mean(y_pred == y_bal) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
