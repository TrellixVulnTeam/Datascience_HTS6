{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libaries and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "advert = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve learnt to implement linear regression models using `statsmodels`…now let’s learn to do it using `scikit-learn`, a commonly used package for machine learning in Python. It has more built-in methods to perform the regular processes associated with regression.\n",
    "\n",
    "In the last step, we manually split our dataset into train and test sets. `scikit-learn` has a built-in method to do this for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary scikit-learn methods\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Build linear regression model using TV and Radio as predictors\n",
    "# Split data into predictors X and output Y\n",
    "predictors = ['TV', 'Radio']\n",
    "X = advert[predictors]\n",
    "Y = advert['Sales']\n",
    "\n",
    "# Split data into training and testing sets using `train_test_split` method\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialise and fit model\n",
    "lm = LinearRegression()\n",
    "lm.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have split the dataset 80:20 (`test_size=0.2`). You can check that the split was done correctly by printing out the shapes of the training and testing arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(testX.shape)\n",
    "print(trainY.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will display the parameters of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'alpha = {lm.intercept_}')\n",
    "print(f'betas = {lm.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lm.coef_` returns an array with our coefficients *β<sub>1</sub>* and *β<sub>2</sub>*. \n",
    "\n",
    "The value of *R<sup>2</sup>* can be returned simply calling `.score`. It turns out to be very close to the value obtained using the `statsmodels` method in the previous step (0.901)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.score(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict sales, pass the test predictors into `.predict()`. An array of 40 predictions (because there are 40 rows in the test dataset) is returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with scikit-learn\n",
    "\n",
    "As stated before, many statistical tools and packages have built-in methods for variable selection (feel free to review the “Multiple Regression with `statsmodels`” step if you need to). If done manually, feature selection is time consuming and tedious, compromising the efficiency of the model.\n",
    "\n",
    "One advantage of using `scikit-learn` is that it has a method for feature selection. This method, called **Recursive Feature Elimination** (**RFE**), works similarly to backward selection.\n",
    "\n",
    "The model is first run with all the variables and certain weights are assigned to all the variables. In the subsequent iterations, the variables with the smallest weights are pruned from the list of variables until the specified number of variables is left.\n",
    "\n",
    "Let’s give it a go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE   # Recursive Feature Elimination\n",
    "from sklearn.svm import SVR                 # Support Vector Regression\n",
    "\n",
    "# Start with all possible predictors\n",
    "predictors = ['TV', 'Radio', 'Newspaper']\n",
    "X = advert[predictors]\n",
    "Y = advert['Sales']\n",
    "\n",
    "# Estimate a linear model\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "\n",
    "# Using RFE, specify 2 predictors for the final model\n",
    "# and 1 predictor to remove at each iteration\n",
    "selector = RFE(estimator, 2, step=1)\n",
    "selector = selector.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the method `SVR` to estimate a linear model. Then, using `RFE` we specify the number of desired variables in the model to be two, and the number of variables to remove at each iteration to be one. \n",
    "\n",
    "For more information about these methods, you can read the documentation [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) and [here](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html).\n",
    "\n",
    "To get the list of selected variables, we call use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns an array of `True`s and `False`s in the order of the `predictors`. In our example, we specified the order of our predictors to be: `predictors = ['TV', 'Radio','Newspaper']`. The output, therefore, means `TV` and `Radio` were selected (`True`) while `Newspaper` was not selected (`False`). \n",
    "\n",
    "This concurs with the variable selection we had done manually!\n",
    "\n",
    "We can also return the predictors’ significance rankings using `ranking_`. Selected variables have a ranking of `1`, while the rest are ranked in descending order of their significance (based on which iteration it was removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've covered quite a lot this lesson! To wrap up, reopen the instructions panel on the left, then press Next Step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
