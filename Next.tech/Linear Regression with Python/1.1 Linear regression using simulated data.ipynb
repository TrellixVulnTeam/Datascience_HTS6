{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Using Simulated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `pandas` and `numpy`, let’s simulate some data and look at how the predicted values (*Y<sub>e</sub>*) differ from the actual value (*Y*).\n",
    "\n",
    "### Simulating data:\n",
    "- For *X*, we generate 100 normally distributed random numbers with mean 1.5 and standard deviation 2.5. \n",
    "\n",
    "- For predicted value *Y<sub>e</sub>*, we assume an intercept (α) of 2 and a slope (β) of 0.3 and we write ![](https://latex.codecogs.com/gif.latex?Y_e%20%3D%202%20+%200.3x)\n",
    "\n",
    "    Later, we will estimate the values of α and β using the least squares method and see how that changes the efficacy of the model. \n",
    "\n",
    "- Though we estimate $Y_e = \\alpha + \\beta X$, in reality Y is rarely perfectly linear. It usually has an error component or **residual** – $Y = \\alpha + \\beta X + K$, where *K* is a random variable and is assumed to be normally distributed.\n",
    "    \n",
    "    Therefore for the actual value *Y*, we add a residual term (`res`), a random variable distributed normally with mean 0 and a standard deviation of 0.5.\n",
    "\n",
    "The following cell shows the code snippet to generate these numbers and convert these three columns in a data frame. Read through the code carefully and run the cell to output a sample of our simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate 'random' data\n",
    "np.random.seed(0)\n",
    "X = 2.5 * np.random.randn(100) + 1.5   # Array of 100 values with mean = 1.5, stddev = 2.5\n",
    "ypred = 2 + 0.3 * X                    # Prediction of Y, assuming a = 2, b = 0.3\n",
    "res = 0.5 * np.random.randn(100)       # Generate 100 residual terms\n",
    "yact = 2 + 0.3 * X + res               # Actual values of Y\n",
    "\n",
    "# Create pandas dataframe to store our X, ypred, and yact values\n",
    "df = pd.DataFrame(\n",
    "    {'X': X,\n",
    "     'ypred': ypred,\n",
    "     'yact': yact}\n",
    ")\n",
    "\n",
    "# Show the first five rows of our dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s plot both the actual output (`yact`) and predicted output (`ypred`) against the input variable (`X`) to see what the difference between `yact` and `ypred` is, and therefore, to see how accurately the proposed equation (`ypred = 2 + 0.3 * X`) has been able to predict the value of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot prediction as blue line, actual values of Y as red markers\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(X, ypred)\n",
    "plt.plot(X, yact, 'ro')\n",
    "plt.title('Actual vs Predicted values from the dummy dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model efficacy\n",
    "\n",
    "How do we know the values we calculate for α and β are giving us a good model? We can explain the total variability in our model with the **Total Sum of Squares** or SST:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%24%5Ctext%7BSST%7D%20%3D%20%5Csum%28%5Ctext%7Byact%7D%20-%20%5Ctext%7Bymean%7D%29%5E2%24)\n",
    "\n",
    "This total error is composed of two terms — the **Regression Sum of Squares** and **Difference Sum of Squares**.\n",
    "\n",
    "The Regression Sum of Squares or SSR is the difference between the regression value and the mean value. This is the difference that the model seeks to explain, and can be written as: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%24%5Ctext%7BSSR%7D%20%3D%20%5Csum%28%5Ctext%7Bypred%7D%20-%20%5Ctext%7Bymean%7D%29%5E2%24)\n",
    "\n",
    "The Difference Sum of Squares or SSD is the unexplained random term:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%24%5Ctext%7BSSD%7D%20%3D%20%5Csum%28%5Ctext%7Byact%7D%20-%20%5Ctext%7Bypred%7D%29%5E2%24)\n",
    "\n",
    "Intuitively, you can see that SST = SSR + SSD, where SSR is the difference explained by the model, SSD is the difference not explained by the model and is random, and SST is the total error.\n",
    "\n",
    "<img src=\"https://github.com/nextdotxyz/linear-regression-with-python/blob/master/00%20Notebooks/1.2%20sst.png?raw=true\" title=\"SST consists of SSR (the variance explained by the model) and SSD (the variance not explained by the model).\" />\n",
    "\n",
    "### *R-Squared*\n",
    "\n",
    "The higher the ratio of SSR to SST, the better the model is. This ratio is quantified by the **coefficient of determination** (also known as ***R<sup>2</sup>*** or ***R*-squared**):\n",
    "\n",
    "*R<sup>2</sup>* = SSR / SST\n",
    "\n",
    "Since SST > SSR, the value of *R<sup>2</sup>* can range from 0 to 1. The closer it is to 1, the better the model. Note that there are many other factors that we need to analyse before we can conclude a linear regression model is effective (we will discuss some at the end of this lesson), but a high *R<sup>2</sup>* is a pretty good indicator.\n",
    "\n",
    "Let’s see what the value of *R<sup>2</sup>* is for our simulated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of Y\n",
    "ymean = np.mean(yact)\n",
    "print(f'Mean of Y = {ymean}')\n",
    "\n",
    "# Calculate SSR and SST\n",
    "df['SSR'] = (df['ypred'] - ymean)**2\n",
    "df['SST'] = (df['yact'] - ymean)**2\n",
    "SSR = df['SSR'].sum()\n",
    "SST = df['SST'].sum()\n",
    "\n",
    "# Calculate R-squared\n",
    "R2 = SSR / SST\n",
    "print(f'R2 = {R2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of *R<sup>2</sup>* comes out to be 0.62, suggesting that `ypred` provides a decent prediction of the `yact`. \n",
    "\n",
    "We have randomly assumed some values for ɑ and β, but these may or may not be the best values. In the next step, we will use the least sum of square method to calculate the optimum value for ɑ and β to see if there is an improvement in *R<sup>2</sup>*.\n",
    "\n",
    "To get started on the next step, go back to the notebook directory in Jupyter by pressing `File` > `Open…` in the toolbar at the top, then open the notebook called `1.2 Least squares using simulated data.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
