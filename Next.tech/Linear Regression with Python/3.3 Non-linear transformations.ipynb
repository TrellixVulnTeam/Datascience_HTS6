{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the output variable doesn't have a direct linear relationship with the predictor variable. They can have quadratic, exponential, logarithmic, or polynomial relationships. In such cases, transforming the variable comes in very handy.\n",
    "\n",
    "The following is a rough guideline on how to spot and handle non-linear relationships:\n",
    "\n",
    "- Plot a scatter plot of the output variable with each of the predictor variables.\n",
    "- If the scatter plot assumes more or less a linear shape then it is linearly related to the output variable.\n",
    "- If the scatter plot assumes a characteristic non-linear shape then transform the variable by applying that function.\n",
    "\n",
    "Let's illustrate this with an example. We will use the `auto.csv` dataset for this. This dataset contains information about miles per gallon (mpg) and horsepower for a number of car models. `mpg` is the predictor variable.\n",
    "\n",
    "Let's import the dataset and take a look at the relationship between `horsepower` and `mpg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `auto` as a pandas dataframe\n",
    "auto = pd.read_csv('auto.csv')\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot to show relationship between horsepower and mpg\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(auto['horsepower'], auto['mpg'], 'ro')\n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel('MPG (Miles Per Gallon)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationship between `horsepower` and `mpg` doesn't seem to have a linear shape.\n",
    "\n",
    "However, for the sake of comparison, let's try and fit a linear model first – i.e. assume that the model is:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Ctext%7Bmpg%7D%20%3D%20%5Calpha%20+%20%5Cbeta_1*%5Ctext%7Bhorsepower%7D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialise and fit linear regression model\n",
    "X = auto['horsepower']\n",
    "Y = auto['mpg']\n",
    "lm = LinearRegression()\n",
    "lm.fit(X[:, np.newaxis], Y)   # see note below\n",
    "\n",
    "print(f'alpha = {lm.intercept_}')\n",
    "print(f'betas = {lm.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that the linear regression method by default requires that *X* be an array of two dimensions. Using `np.newaxis`, we can create a new dimension for it to function properly.\n",
    "\n",
    "The line of best fit can be plotted by the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot to show relationship between horsepower and mpg and predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(auto['horsepower'], auto['mpg'], 'ro')\n",
    "plt.plot(X, lm.predict(X[:, np.newaxis]))\n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel('MPG (Miles Per Gallon)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is not very efficient – the *R<sup>2</sup>* for this model is 0.6059, and the RSE is 4.9058 (20.92%) error. See if you can figure out how to calculate these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R2 score\n",
    "\n",
    "# Calculate RSE and error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scatter plot, it looks like the relationship between `horsepower` and `mpg` could linearised by taking the square-root of `horsepower` – if we assume a model in the form ![](https://latex.codecogs.com/gif.latex?%5Ctext%7Bmpg%7D%20%3D%20%5Calpha%20+%20%5Cbeta_1*%5Csqrt%5Ctext%7Bhorsepower%7D) the model may improve. Let’s give it a go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X by taking the square root\n",
    "X2 = np.sqrt(auto['horsepower'])\n",
    "Y2 = auto['mpg']\n",
    "lm2 = LinearRegression()\n",
    "lm2.fit(X2[:, np.newaxis], Y2)\n",
    "\n",
    "print(f'alpha = {lm2.intercept_}')\n",
    "print(f'beta = {lm2.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if you can work out the R2, RSE, and error on your own!\n",
    "# Calculate R2 score\n",
    "\n",
    "# Calculate RSE and error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *R<sup>2</sup>* value for this model comes out to be around 0.6437, and the RSE is 4.6648 (19.90% error) – a slight improvement!\n",
    "\n",
    "Let’s plot our model to see how transforming `horsepower` has helped our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot to show relationship between horsepower and mpg and predictions\n",
    "ypred = lm2.predict(X2[:, np.newaxis])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(X2, Y2, 'ro')\n",
    "plt.plot(X2, ypred)\n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel('MPG (Miles Per Gallon)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still room for improvement. The scatter plot shows that there is still a curve in our data. We may be able to improve our model by taking the log of `horsepower`, i.e. assuming an equation:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Ctext%7Bmpg%7D%20%3D%20%5Calpha%20+%20%5Cbeta_1*%5Clog%28%5Ctext%7Bhorsepower%7D%29)\n",
    "\n",
    "See if you can perform this **log-transform** on your own! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X by taking the log - note: to take log, you can use np.log()\n",
    "\n",
    "# Initialise and fit a linar regression model\n",
    "\n",
    "# Print alpha and beta\n",
    "\n",
    "# Calculate R2 score\n",
    "\n",
    "# Calculate RSE and error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot new prediction against log-transformed relationship\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have found a *R<sup>2</sup>* of 0.6683, RSE of 4.5007 (19.19% error), and your plot should look like the following:\n",
    "\n",
    "![](https://github.com/nextdotxyz/linear-regression-with-python/blob/master/00%20Notebooks/3.4%20log.png?raw=true)\n",
    "\n",
    "Finally, we can try a model with a **polynomial fit** using `scikit-learn`'s `PolynomialFeatures` method. This allows us to **power-transform** X to a specified degree. We will try power-transforming `horsepower` to the second degree, i.e. assuming a model that can be written as:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Ctext%7Bmpg%7D%20%3D%20%5Calpha%20+%20%5Cbeta_1*%5Ctext%7Bhorsepower%7D%20+%20%5Cbeta_2*%5Ctext%7Bhorsepower%7D%5E2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)         # set number of degrees to 2\n",
    "X4 = poly.fit_transform(X[:, np.newaxis])   # transform X\n",
    "Y4 = auto['mpg']                            # Y remains un-transformed\n",
    "\n",
    "# Intialise and fit new model\n",
    "lm4 = LinearRegression()\n",
    "lm4.fit(X4, Y4)\n",
    "\n",
    "# Print parameters\n",
    "print(f'alpha = {lm4.intercept_}')\n",
    "print(f'beta = {lm4.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the model:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Ctext%7Bmpg%7D%20%3D%2056.9%20-0.4662%20*%5Ctext%7Bhorsepower%7D%20+%200.001*%5Ctext%7Bhorsepower%7D%5E2)\n",
    "\n",
    "We end up with a model with the highest *R<sup>2</sup>* and lowest RSE and error percentage! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared\n",
    "print(f'R2 = {lm4.score(X4, Y4)}')\n",
    "\n",
    "# RSE & Error\n",
    "SSD = (Y4 - lm4.predict(X4))**2\n",
    "RSE = np.sqrt(np.sum(SSD) / 389)\n",
    "ymean = np.mean(Y4)\n",
    "error = RSE / ymean\n",
    "print(f'RSE = {RSE}\\nError = {np.round(error, 4)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try plotting this to see how our prediction looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = lm4.predict(X4)                    # store predictions\n",
    "newX, newY = zip(*sorted(zip(X, ypred)))   # sort values for plotting\n",
    "\n",
    "# Plot polynomial regression against original data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(X, Y, 'ro')\n",
    "plt.plot(newX, newY)\n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel('MPG (Miles Per Gallon)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good!\n",
    "\n",
    "You can try to further improve the model by playing with the number of degrees in your polynomial regression i.e. by changing `poly = PolynomialFeatures(degree=n)`. Keep in mind, however, a higher degree may fit better on training data but be poor at generalising to other data (remember overfitting?). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to change the polynomial degree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've talked about how to handle a lot of issues and other considerations in implementing linear regression models in this lesson! To wrap up, reopen the instructions panel on the left, then press Next Step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
